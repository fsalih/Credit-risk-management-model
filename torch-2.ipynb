{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d816ab6e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb4c623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b055ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e191c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b610049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3eabb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7209, 0.9404, 0.5645],\n",
      "        [0.3859, 0.4065, 0.2243],\n",
      "        [0.7746, 0.4664, 0.1597],\n",
      "        [0.1633, 0.9118, 0.7845],\n",
      "        [0.3802, 0.6604, 0.3582]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2879ada",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca76079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1944bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "# from torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96823dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcb5de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f104f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6686f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "869e9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('clean-train-5.pkl')\n",
    "test = pd.read_pickle('clean-test-5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f32e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'flag'\n",
    "features = train.drop(columns=target).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dafdfeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].dtype == bool:\n",
    "        train[col] = train[col].astype(np.int8)\n",
    "        test[col] = test[col].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1f6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[features]\n",
    "y = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f1727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7c0eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10678aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем тренировочный torch.dataset\n",
    "train_dataset = MyDataset(X.values, y.values)\n",
    "\n",
    "# Преобразуем тестовую выборку в torch-тензоры всю целиком\n",
    "X_test_tensor = torch.from_numpy(test[features].values.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(test[target].values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eed026e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "\n",
    "# Создайте Dataloader для тренировочной выборки на основе экземпляра train_dataset\n",
    "# Делайте как в видео, размер батча – batch_size\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a5b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionNet(\n",
      "  (hidden1): Linear(in_features=411, out_features=411, bias=True)\n",
      "  (f1): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (batchnorm): BatchNorm1d(411, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (hidden2): Linear(in_features=411, out_features=12, bias=True)\n",
      "  (f2): ReLU()\n",
      "  (hidden3): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (f3): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(in_features=input_dim, out_features=hidden_dims[0], bias=True)\n",
    "        self.f1 = nn.ReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_dims[0])\n",
    "        \n",
    "        self.hidden2 = nn.Linear(in_features=hidden_dims[0], out_features=hidden_dims[1], bias=True)\n",
    "        self.f2 = nn.ReLU()\n",
    "        \n",
    "        # self.batchnorm2 = nn.BatchNorm1d(hidden_dims[1])\n",
    "        \n",
    "        self.hidden3 = nn.Linear(in_features=hidden_dims[1], out_features=hidden_dims[2], bias=True)\n",
    "        self.f3 = nn.ReLU()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.output = nn.Linear(in_features=hidden_dims[2], out_features=output_dim, bias=True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.f1(self.hidden1(X))\n",
    "        \n",
    "        # X = self.batchnorm(X)\n",
    "        # X = self.dropout(X)\n",
    "        \n",
    "        X = self.f2(self.hidden2(X))\n",
    "        # X = self.batchnorm2(X)\n",
    "        \n",
    "        X = self.f3(self.hidden3(X))\n",
    "        X = self.output(X)\n",
    "        X = self.sigmoid(X)\n",
    "        # X = self.softmax(X)\n",
    "        return X\n",
    "\n",
    "torch.manual_seed(RS)\n",
    "\n",
    "# Объявляем экземпляр класса нейронной сети\n",
    "model = RegressionNet(411, (411, 12, 6), 1)\n",
    "\n",
    "model.to(device)  # ++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Должен напечатать следующее:\n",
    "#\n",
    "# RegressionNet(\n",
    "#   (hidden1): Linear(in_features=8, out_features=24, bias=True)\n",
    "#   (f1): ReLU()\n",
    "#   (hidden2): Linear(in_features=24, out_features=12, bias=True)\n",
    "#   (f2): ReLU()\n",
    "#   (hidden3): Linear(in_features=12, out_features=6, bias=True)\n",
    "#   (f3): ReLU()\n",
    "#   (output): Linear(in_features=6, out_features=1, bias=True)\n",
    "# )\n",
    "#\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f50ee7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_train 0.09852542728185654    rocauc 0.7525375453496241\n",
      "epoch 1 loss_train 0.09896870702505112    rocauc 0.7578759265914918\n",
      "epoch 2 loss_train 0.15473532676696777    rocauc 0.7591959520880971\n",
      "epoch 3 loss_train 0.19849887490272522    rocauc 0.7602724820394284\n",
      "epoch 4 loss_train 0.15640613436698914    rocauc 0.7616308907118239\n",
      "epoch 5 loss_train 0.08709590882062912    rocauc 0.7613870660537999\n",
      "epoch 6 loss_train 0.1165982186794281    rocauc 0.7605847434084356\n",
      "epoch 7 loss_train 0.1833702176809311    rocauc 0.7597703671664352\n",
      "epoch 8 loss_train 0.16251744329929352    rocauc 0.7593558791493179\n",
      "epoch 9 loss_train 0.09117133915424347    rocauc 0.7564337574075118\n",
      "CPU times: total: 14min 17s\n",
      "Wall time: 14min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создайте объект класса, который реализует среднеквадратичную ошибку (MSE).\n",
    "# loss_fn = nn.MSELoss()  # ВАШ КОД ЗДЕСЬ\n",
    "loss_fn = nn.BCELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "X_test_gpu = X_test_tensor.to(device)\n",
    "\n",
    "\n",
    "# Создаём оптимизатор. Тут будем использовать вариацию стохастического \n",
    "# градиентного спуска Adam. Это адаптивный алгоритм, который выбирает\n",
    "# шаг изменения весов (learning rate) в зависимости от текущей ситуации. \n",
    "# Это очень эффективный алгоритм, который в большинстве случаев работает \n",
    "# лучше, чем обычный градиентный спуск с постоянным шагом. В этой задаче – \n",
    "# точно лучше. Если хотите убедиться, замените Adam на torch.optim.SDG\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Делаем 100 эпох\n",
    "num_epochs = 10\n",
    "\n",
    "# Сюда будем сохранять значение функции потерь на тестовой выборке\n",
    "# после каждой эпохи обучения\n",
    "loss_test = []\n",
    "loss_train = []\n",
    "\n",
    "# Реализуйте тренировочный цикл\n",
    "for i in range(num_epochs):  # ВАШ КОД ЗДЕСЬ\n",
    "    for X, y in train_dataloader:  # ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "    # Реализуйте все шаги тренировочного цикла PyTorch\n",
    "    #\n",
    "    # ВАШ КОД ЗДЕСЬ\n",
    "    #\n",
    "        X_g = X.to(device)\n",
    "        y_g = y.to(device)\n",
    "        \n",
    "        pred = model(X_g)\n",
    "        loss = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_tr = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "    loss_train.append(loss_tr.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_gpu).to('cpu').detach().numpy()\n",
    "        rocauc = roc_auc_score(test[target], pred)\n",
    "        loss_test.append(rocauc)\n",
    "    # Конец эпохи: считаем функцию потерь на тестовой выборке, \n",
    "    # сохраняем в список, чтобы потом нарисовать график\n",
    "#         loss = loss_fn(\n",
    "#             model(X_test_tensor),\n",
    "#             y_test_tensor.unsqueeze(-1)\n",
    "#         ).item()\n",
    "#         loss_test.append(loss)\n",
    "    print(f'epoch {i} loss_train {loss_tr}    rocauc {rocauc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "422a6fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_train 0.139598548412323    rocauc 0.7347405704234224\n",
      "epoch 1 loss_train 0.14240841567516327    rocauc 0.7371303518774304\n",
      "epoch 2 loss_train 0.1302129626274109    rocauc 0.7381833096466305\n",
      "epoch 3 loss_train 0.13290223479270935    rocauc 0.7406819385860204\n",
      "epoch 4 loss_train 0.1422562152147293    rocauc 0.74048390600069\n",
      "epoch 5 loss_train 0.1415494978427887    rocauc 0.74226846205861\n",
      "epoch 6 loss_train 0.13240188360214233    rocauc 0.7422218594875989\n",
      "epoch 7 loss_train 0.13692660629749298    rocauc 0.7434756967774446\n",
      "epoch 8 loss_train 0.1358546018600464    rocauc 0.7435731993787332\n",
      "epoch 9 loss_train 0.14681376516819    rocauc 0.7457567993248148\n"
     ]
    }
   ],
   "source": [
    "# Дообучение\n",
    "for i in range(num_epochs):  # ВАШ КОД ЗДЕСЬ\n",
    "    for X, y in train_dataloader:  # ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "    # Реализуйте все шаги тренировочного цикла PyTorch\n",
    "    #\n",
    "    # ВАШ КОД ЗДЕСЬ\n",
    "    #\n",
    "        X_g = X.to(device)\n",
    "        y_g = y.to(device)\n",
    "        \n",
    "        pred = model(X_g)\n",
    "        loss = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_tr = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "    loss_train.append(loss_tr.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_gpu).to('cpu').detach().numpy()\n",
    "        rocauc = roc_auc_score(test[target], pred)\n",
    "    # Конец эпохи: считаем функцию потерь на тестовой выборке, \n",
    "    # сохраняем в список, чтобы потом нарисовать график\n",
    "#         loss = loss_fn(\n",
    "#             model(X_test_tensor),\n",
    "#             y_test_tensor.unsqueeze(-1)\n",
    "#         ).item()\n",
    "#         loss_test.append(loss)\n",
    "    print(f'epoch {i} loss_train {loss_tr}    rocauc {rocauc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b082abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_train 0.13617216050624847    rocauc 0.7459803832060079\n",
      "epoch 1 loss_train 0.1432255655527115    rocauc 0.7450552715085272\n",
      "epoch 2 loss_train 0.12980107963085175    rocauc 0.7469279809197503\n",
      "epoch 3 loss_train 0.13661377131938934    rocauc 0.7470309522652732\n",
      "epoch 4 loss_train 0.13791076838970184    rocauc 0.7470900427585756\n",
      "epoch 5 loss_train 0.14174149930477142    rocauc 0.7468127751513656\n",
      "epoch 6 loss_train 0.13691213726997375    rocauc 0.747287434199946\n",
      "epoch 7 loss_train 0.1382875144481659    rocauc 0.7482137291773514\n",
      "epoch 8 loss_train 0.1392667293548584    rocauc 0.749108094409934\n",
      "epoch 9 loss_train 0.13881823420524597    rocauc 0.7475037263560225\n",
      "epoch 10 loss_train 0.1468576192855835    rocauc 0.7500075910849628\n",
      "epoch 11 loss_train 0.1429845243692398    rocauc 0.7493948827839907\n",
      "epoch 12 loss_train 0.13971205055713654    rocauc 0.7486521569092862\n",
      "epoch 13 loss_train 0.13620367646217346    rocauc 0.7488540371159531\n",
      "epoch 14 loss_train 0.1422923058271408    rocauc 0.748368655423909\n",
      "epoch 15 loss_train 0.13401582837104797    rocauc 0.7501343578089981\n",
      "epoch 16 loss_train 0.1346486657857895    rocauc 0.749337767562426\n",
      "epoch 17 loss_train 0.13769245147705078    rocauc 0.7495989573822948\n",
      "epoch 18 loss_train 0.13268840312957764    rocauc 0.7489422818654144\n",
      "epoch 19 loss_train 0.1419791877269745    rocauc 0.7494954491136531\n",
      "epoch 20 loss_train 0.13676851987838745    rocauc 0.7487334449626903\n",
      "epoch 21 loss_train 0.14022855460643768    rocauc 0.7486343330350476\n",
      "epoch 22 loss_train 0.13158775866031647    rocauc 0.7474281842295573\n",
      "epoch 23 loss_train 0.12712597846984863    rocauc 0.7494881697081685\n",
      "epoch 24 loss_train 0.12708279490470886    rocauc 0.7486904432235468\n",
      "epoch 25 loss_train 0.12983374297618866    rocauc 0.7490429800133368\n",
      "epoch 26 loss_train 0.13408325612545013    rocauc 0.7488221023386596\n",
      "epoch 27 loss_train 0.12933331727981567    rocauc 0.7498440488700766\n",
      "epoch 28 loss_train 0.14386630058288574    rocauc 0.7481558331472414\n",
      "epoch 29 loss_train 0.1451391577720642    rocauc 0.7478305650064281\n"
     ]
    }
   ],
   "source": [
    "# Дообучение\n",
    "for i in range(30):  # ВАШ КОД ЗДЕСЬ\n",
    "    for X, y in train_dataloader:  # ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "    # Реализуйте все шаги тренировочного цикла PyTorch\n",
    "    #\n",
    "    # ВАШ КОД ЗДЕСЬ\n",
    "    #\n",
    "        X_g = X.to(device)\n",
    "        y_g = y.to(device)\n",
    "        \n",
    "        pred = model(X_g)\n",
    "        loss = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_tr = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "    loss_train.append(loss_tr.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_gpu).to('cpu').detach().numpy()\n",
    "        rocauc = roc_auc_score(test[target], pred)\n",
    "    # Конец эпохи: считаем функцию потерь на тестовой выборке, \n",
    "    # сохраняем в список, чтобы потом нарисовать график\n",
    "#         loss = loss_fn(\n",
    "#             model(X_test_tensor),\n",
    "#             y_test_tensor.unsqueeze(-1)\n",
    "#         ).item()\n",
    "#         loss_test.append(loss)\n",
    "    print(f'epoch {i} loss_train {loss_tr}    rocauc {rocauc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3cfcc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt = len(loss_train)\n",
    "# step = np.arange(0, num_epochs)\n",
    "step = np.arange(0, cnt)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "# Рисуем зависимость ошибки от эпохи обучения\n",
    "plt.plot(step, np.array(loss_train))\n",
    "plt.plot(step, np.array(loss_train))\n",
    "\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328b1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Конец эпохи: считаем функцию потерь на тестовой выборке, \n",
    "    # сохраняем в список, чтобы потом нарисовать график\n",
    "        loss = loss_fn(\n",
    "            model(X_test_tensor),\n",
    "            y_test_tensor.unsqueeze(-1)\n",
    "        ).item()\n",
    "        loss_test.append(loss)\n",
    "        print(f'epoch {i} loss_train {loss_tr}    loss {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b369bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0932df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_test_tensor.to(device)).to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "946ad1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6507655996022356"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[target], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ac17141",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48ee0b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d3a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30d615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f96f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a79ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971dd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdff88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af513d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "#     def input_size(self):\n",
    "#         return self.X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "039b885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditNN(nn.Module):\n",
    "    def __init__(self, input_size=411, hidden_1_size=1000, out_size=1):\n",
    "        super(CreditNN, self).__init__()\n",
    "        self.to(device)\n",
    "        self.input_size = input_size\n",
    "        self.dense1 = nn.Linear(self.input_size, hidden_1_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(hidden_1_size, out_size)\n",
    "#         self.normalize = nn.BatchNorm1d(hidden_1_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "#         x = x.view(-1, self.dense1.out_features)\n",
    "#         x = self.normalize(x)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, data_loader, optimizer, criterion, epochs=10, verbose=True):\n",
    "        self.__init__(input_size=data_loader.dataset.X.shape[1])\n",
    "        print(self.input_size)\n",
    "        for epoch in range(epochs):\n",
    "            for x_batch, y_batch in data_loader:\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = self(x_batch.to(device))\n",
    "                loss = criterion(y_batch, y_pred[:, 0])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if verbose: \n",
    "                print(f'Epoch #{epoch}: \\tloss: {loss.item():.5f}')\n",
    "                print(y_batch)\n",
    "                print(y_pred[:, 0])\n",
    "#                 print(loss.item())\n",
    "        print(f'Training loss: {loss.item():.4f}')\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self(torch.from_numpy(X.astype(np.float32)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b532ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab331ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nn = CreditNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05450c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a3d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b98da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.BCELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fad9bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditNN(\n",
       "  (dense1): Linear(in_features=411, out_features=1000, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dense2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42317297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7141f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8a251f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3_000\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4715ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2100000, 411])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbc1bc09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n",
      "Epoch #0: \tloss: 116.39467\n",
      "tensor([0., 0., 1.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([11.0980, 12.0988,  9.7547,  ..., 12.1003,  9.9975, 11.6913],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #1: \tloss: 116.26477\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([ 7.8907,  6.5455, 12.4232,  ..., 10.0564, 10.8875,  7.9546],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #2: \tloss: 117.20963\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([ 6.2683,  9.9263, 12.1005,  ...,  9.3983,  9.4393, 12.3862],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #3: \tloss: 117.73159\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([ 7.5290, 11.6397, 12.5696,  ..., 10.8295, 17.5697,  9.8097],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #4: \tloss: 117.52104\n",
      "tensor([0., 0., 0.,  ..., 0., 1., 0.], device='cuda:0')\n",
      "tensor([12.2983,  8.1309,  8.5450,  ...,  9.9426, 10.8708, 10.7213],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #5: \tloss: 116.22420\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([10.7470, 11.3275, 19.0195,  ...,  9.5132, 10.3796, 11.4225],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #6: \tloss: 116.03967\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([11.9706,  9.3158, 11.0113,  ..., 10.4632, 10.2728,  8.8581],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #7: \tloss: 116.54625\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([ 9.0696, 12.2570,  9.1941,  ..., 11.1210, 11.4142, 13.5936],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #8: \tloss: 116.81273\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([ 8.1283, 12.0026, 11.4625,  ..., 11.6358,  6.3572, 11.0242],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Epoch #9: \tloss: 115.20318\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "tensor([ 9.3472,  4.9260, 10.6744,  ...,  9.9595, 10.7688, 11.9896],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Training loss: 115.2032\n",
      "CPU times: total: 10min 51s\n",
      "Wall time: 10min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_nn.fit(train_dataloader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "471aa778",
   "metadata": {},
   "outputs": [],
   "source": [
    "lss_pred = my_nn(torch.from_numpy(test[features].values.astype(np.float32)).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6c289d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lss_pred.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac1e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783f765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "373756ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5356464384658775"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[target], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8399c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c63605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.f1 = nn.ReLU()\n",
    "        \n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.f2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.f1(self.hidden(x))\n",
    "        x = self.f2(self.output(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34596c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = MyNet(2, 16, 1)\n",
    "\n",
    "print(my_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581eb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_net(torch.from_numpy(X_test.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cca9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(my_net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4befde",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in train_dataloader:\n",
    "        \n",
    "        pred = my_net(X)\n",
    "        \n",
    "        loss = loss_fn(pred, y.unsqueeze(-1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    loss = loss_fn(pred, y.unsqueeze(-1))\n",
    "    loss_values.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad52083",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = np.linspace(0, num_epochs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "plt.plot(step, np.array(loss_values))\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021aac04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c31f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf91b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0776c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_train 0.59307461977005    rocauc 0.5631392618904505\n",
      "epoch 1 loss_train 0.3998393416404724    rocauc 0.5920715957311883\n",
      "epoch 2 loss_train 0.2785755395889282    rocauc 0.6711860498985128\n",
      "epoch 3 loss_train 0.19279980659484863    rocauc 0.6903045202897271\n",
      "epoch 4 loss_train 0.15606869757175446    rocauc 0.7113603221724513\n",
      "epoch 5 loss_train 0.1487884670495987    rocauc 0.720374700532411\n",
      "epoch 6 loss_train 0.1459091454744339    rocauc 0.7303886727048639\n",
      "epoch 7 loss_train 0.14826242625713348    rocauc 0.7301517125891628\n",
      "epoch 8 loss_train 0.13726936280727386    rocauc 0.7422040803103565\n",
      "epoch 9 loss_train 0.14441458880901337    rocauc 0.7448896232498196\n",
      "CPU times: total: 11min 44s\n",
      "Wall time: 11min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создайте объект класса, который реализует среднеквадратичную ошибку (MSE).\n",
    "# loss_fn = nn.MSELoss()  # ВАШ КОД ЗДЕСЬ\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "X_test_gpu = X_test_tensor.to(device)\n",
    "\n",
    "\n",
    "# Создаём оптимизатор. Тут будем использовать вариацию стохастического \n",
    "# градиентного спуска Adam. Это адаптивный алгоритм, который выбирает\n",
    "# шаг изменения весов (learning rate) в зависимости от текущей ситуации. \n",
    "# Это очень эффективный алгоритм, который в большинстве случаев работает \n",
    "# лучше, чем обычный градиентный спуск с постоянным шагом. В этой задаче – \n",
    "# точно лучше. Если хотите убедиться, замените Adam на torch.optim.SDG\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Делаем 100 эпох\n",
    "num_epochs = 10\n",
    "\n",
    "# Сюда будем сохранять значение функции потерь на тестовой выборке\n",
    "# после каждой эпохи обучения\n",
    "loss_test = []\n",
    "loss_train = []\n",
    "\n",
    "# Реализуйте тренировочный цикл\n",
    "for i in range(num_epochs):  # ВАШ КОД ЗДЕСЬ\n",
    "    for X, y in train_dataloader:  # ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "    # Реализуйте все шаги тренировочного цикла PyTorch\n",
    "    #\n",
    "    # ВАШ КОД ЗДЕСЬ\n",
    "    #\n",
    "        X_g = X.to(device)\n",
    "        y_g = y.to(device)\n",
    "        \n",
    "        pred = model(X_g)\n",
    "        loss = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_tr = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "    loss_train.append(loss_tr.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_gpu).to('cpu').detach().numpy()\n",
    "        rocauc = roc_auc_score(test[target], pred)\n",
    "    # Конец эпохи: считаем функцию потерь на тестовой выборке, \n",
    "    # сохраняем в список, чтобы потом нарисовать график\n",
    "#         loss = loss_fn(\n",
    "#             model(X_test_tensor),\n",
    "#             y_test_tensor.unsqueeze(-1)\n",
    "#         ).item()\n",
    "#         loss_test.append(loss)\n",
    "    print(f'epoch {i} loss_train {loss_tr}    rocauc {rocauc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "747af21d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_train -0.37944909930229187    rocauc 0.6827021592018724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss_train -0.38222846388816833    rocauc 0.7164108036940022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss_train -0.3840351998806    rocauc 0.7286779110992091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss_train -0.37969309091567993    rocauc 0.7301265090027421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss_train -0.3792288601398468    rocauc 0.735871961987474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 loss_train -0.38075873255729675    rocauc 0.7385811564200825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 loss_train -0.38166189193725586    rocauc 0.7361765148562248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 loss_train -0.3820490539073944    rocauc 0.7439058370946375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 loss_train -0.38144537806510925    rocauc 0.7420210612260202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss_train -0.3821074068546295    rocauc 0.7411221680506287\n",
      "CPU times: total: 11min 47s\n",
      "Wall time: 11min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создайте объект класса, который реализует среднеквадратичную ошибку (MSE).\n",
    "# loss_fn = nn.MSELoss()  # ВАШ КОД ЗДЕСЬ\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.KLDivLoss()\n",
    "\n",
    "X_test_gpu = X_test_tensor.to(device)\n",
    "\n",
    "\n",
    "# Создаём оптимизатор. Тут будем использовать вариацию стохастического \n",
    "# градиентного спуска Adam. Это адаптивный алгоритм, который выбирает\n",
    "# шаг изменения весов (learning rate) в зависимости от текущей ситуации. \n",
    "# Это очень эффективный алгоритм, который в большинстве случаев работает \n",
    "# лучше, чем обычный градиентный спуск с постоянным шагом. В этой задаче – \n",
    "# точно лучше. Если хотите убедиться, замените Adam на torch.optim.SDG\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Делаем 100 эпох\n",
    "num_epochs = 10\n",
    "\n",
    "# Сюда будем сохранять значение функции потерь на тестовой выборке\n",
    "# после каждой эпохи обучения\n",
    "loss_test = []\n",
    "loss_train = []\n",
    "\n",
    "# Реализуйте тренировочный цикл\n",
    "for i in range(num_epochs):  # ВАШ КОД ЗДЕСЬ\n",
    "    for X, y in train_dataloader:  # ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "    # Реализуйте все шаги тренировочного цикла PyTorch\n",
    "    #\n",
    "    # ВАШ КОД ЗДЕСЬ\n",
    "    #\n",
    "        X_g = X.to(device)\n",
    "        y_g = y.to(device)\n",
    "        \n",
    "        pred = model(X_g)\n",
    "        loss = loss_fn(y_g.unsqueeze(-1), pred)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_tr = loss_fn(y_g.unsqueeze(-1), pred)\n",
    "    loss_train.append(loss_tr.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_gpu).to('cpu').detach().numpy()\n",
    "        rocauc = roc_auc_score(test[target], pred)\n",
    "        loss_test.append(rocauc)\n",
    "    # Конец эпохи: считаем функцию потерь на тестовой выборке, \n",
    "    # сохраняем в список, чтобы потом нарисовать график\n",
    "#         loss = loss_fn(\n",
    "#             model(X_test_tensor),\n",
    "#             y_test_tensor.unsqueeze(-1)\n",
    "#         ).item()\n",
    "#         loss_test.append(loss)\n",
    "    print(f'epoch {i} loss_train {loss_tr}    rocauc {rocauc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "677e420d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss_train 0.08613904565572739    rocauc 0.751999714997233\n",
      "epoch 1 loss_train 0.13183069229125977    rocauc 0.7566377822041987\n",
      "epoch 2 loss_train 0.1615244299173355    rocauc 0.7597330150879396\n",
      "epoch 3 loss_train 0.1339513063430786    rocauc 0.760743667691282\n",
      "epoch 4 loss_train 0.1613963395357132    rocauc 0.7618317727937988\n",
      "epoch 5 loss_train 0.11829637736082077    rocauc 0.7617187928023512\n",
      "epoch 6 loss_train 0.16194510459899902    rocauc 0.7617747471466019\n",
      "epoch 7 loss_train 0.1757342666387558    rocauc 0.7588868788342622\n",
      "epoch 8 loss_train 0.13757367432117462    rocauc 0.7594788017693348\n",
      "epoch 9 loss_train 0.13235490024089813    rocauc 0.7573768005730903\n",
      "epoch 10 loss_train 0.13063859939575195    rocauc 0.7583590725498827\n",
      "epoch 11 loss_train 0.11811397224664688    rocauc 0.7562705914915506\n",
      "epoch 12 loss_train 0.14084723591804504    rocauc 0.7534233498087161\n",
      "epoch 13 loss_train 0.11459673196077347    rocauc 0.7512250569426394\n",
      "epoch 14 loss_train 0.13819751143455505    rocauc 0.747392307043714\n",
      "epoch 15 loss_train 0.1532078981399536    rocauc 0.7466020843514347\n",
      "epoch 16 loss_train 0.07904097437858582    rocauc 0.7449301802544641\n",
      "epoch 17 loss_train 0.098113514482975    rocauc 0.7431308172613291\n",
      "epoch 18 loss_train 0.10351602733135223    rocauc 0.7414518395310021\n",
      "epoch 19 loss_train 0.10876497626304626    rocauc 0.7425702066103945\n",
      "epoch 20 loss_train 0.10943201184272766    rocauc 0.734988658720346\n",
      "epoch 21 loss_train 0.19533613324165344    rocauc 0.7361800408323482\n",
      "epoch 22 loss_train 0.15658040344715118    rocauc 0.7345867427345166\n",
      "epoch 23 loss_train 0.07081831991672516    rocauc 0.7341830812209533\n",
      "epoch 24 loss_train 0.10303923487663269    rocauc 0.730495339056192\n",
      "epoch 25 loss_train 0.1420980840921402    rocauc 0.735365798753487\n",
      "epoch 26 loss_train 0.14288753271102905    rocauc 0.7258351122400855\n",
      "epoch 27 loss_train 0.119383305311203    rocauc 0.7266035591979108\n",
      "epoch 28 loss_train 0.10144734382629395    rocauc 0.7249070663597625\n",
      "epoch 29 loss_train 0.1360136717557907    rocauc 0.7200551928928599\n",
      "epoch 30 loss_train 0.07933534681797028    rocauc 0.7229901417346482\n",
      "epoch 31 loss_train 0.1521400511264801    rocauc 0.7186592544542729\n",
      "epoch 32 loss_train 0.13353529572486877    rocauc 0.7184331140239402\n",
      "epoch 33 loss_train 0.09027200937271118    rocauc 0.7206725034151842\n",
      "epoch 34 loss_train 0.13185812532901764    rocauc 0.7187373312503555\n",
      "epoch 35 loss_train 0.12232799828052521    rocauc 0.7123409886107706\n",
      "epoch 36 loss_train 0.13743554055690765    rocauc 0.7112817735687289\n",
      "epoch 37 loss_train 0.11407198011875153    rocauc 0.7124898925593737\n",
      "epoch 38 loss_train 0.07214104384183884    rocauc 0.7126528547234099\n",
      "epoch 39 loss_train 0.09668606519699097    rocauc 0.7138356635078014\n",
      "epoch 40 loss_train 0.09736359119415283    rocauc 0.7067531451534131\n",
      "epoch 41 loss_train 0.12265230715274811    rocauc 0.7069212183594507\n",
      "epoch 42 loss_train 0.17095398902893066    rocauc 0.7002840412151357\n",
      "epoch 43 loss_train 0.10922632366418839    rocauc 0.7097930927228826\n",
      "epoch 44 loss_train 0.07641468942165375    rocauc 0.7065496861940035\n",
      "epoch 45 loss_train 0.08847343921661377    rocauc 0.7033497950048617\n",
      "epoch 46 loss_train 0.10589095205068588    rocauc 0.6994663535894914\n",
      "epoch 47 loss_train 0.1116926372051239    rocauc 0.7004023169889539\n",
      "epoch 48 loss_train 0.12799547612667084    rocauc 0.6977105794931366\n",
      "epoch 49 loss_train 0.14615647494792938    rocauc 0.697413107112003\n",
      "CPU times: total: 59min 50s\n",
      "Wall time: 58min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создайте объект класса, который реализует среднеквадратичную ошибку (MSE).\n",
    "# loss_fn = nn.MSELoss()  # ВАШ КОД ЗДЕСЬ\n",
    "loss_fn = nn.BCELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "X_test_gpu = X_test_tensor.to(device)\n",
    "\n",
    "\n",
    "# Создаём оптимизатор. Тут будем использовать вариацию стохастического \n",
    "# градиентного спуска Adam. Это адаптивный алгоритм, который выбирает\n",
    "# шаг изменения весов (learning rate) в зависимости от текущей ситуации. \n",
    "# Это очень эффективный алгоритм, который в большинстве случаев работает \n",
    "# лучше, чем обычный градиентный спуск с постоянным шагом. В этой задаче – \n",
    "# точно лучше. Если хотите убедиться, замените Adam на torch.optim.SDG\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Делаем 100 эпох\n",
    "num_epochs = 50\n",
    "\n",
    "# Сюда будем сохранять значение функции потерь на тестовой выборке\n",
    "# после каждой эпохи обучения\n",
    "loss_test = []\n",
    "loss_train = []\n",
    "\n",
    "# Реализуйте тренировочный цикл\n",
    "for i in range(num_epochs):  # ВАШ КОД ЗДЕСЬ\n",
    "    for X, y in train_dataloader:  # ВАШ КОД ЗДЕСЬ\n",
    "\n",
    "    # Реализуйте все шаги тренировочного цикла PyTorch\n",
    "    #\n",
    "    # ВАШ КОД ЗДЕСЬ\n",
    "    #\n",
    "        X_g = X.to(device)\n",
    "        y_g = y.to(device)\n",
    "        \n",
    "        pred = model(X_g)\n",
    "        loss = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_tr = loss_fn(pred, y_g.unsqueeze(-1))\n",
    "    loss_train.append(loss_tr.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_gpu).to('cpu').detach().numpy()\n",
    "        rocauc = roc_auc_score(test[target], pred)\n",
    "        loss_test.append(rocauc)\n",
    "    # Конец эпохи: считаем функцию потерь на тестовой выборке, \n",
    "    # сохраняем в список, чтобы потом нарисовать график\n",
    "#         loss = loss_fn(\n",
    "#             model(X_test_tensor),\n",
    "#             y_test_tensor.unsqueeze(-1)\n",
    "#         ).item()\n",
    "#         loss_test.append(loss)\n",
    "    print(f'epoch {i} loss_train {loss_tr}    rocauc {rocauc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7bc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
